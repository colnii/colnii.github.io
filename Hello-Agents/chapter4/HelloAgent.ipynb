{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2bb41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- è°ƒç”¨LLM ---\n",
      "ğŸ§  æ­£åœ¨è°ƒç”¨ doubao-1.5-pro-256k-250115 æ¨¡å‹...\n",
      "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quick_sort(left) + middle + quick_sort(right)\n",
      "```\n",
      "\n",
      "ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼š\n",
      "```python\n",
      "# ç¤ºä¾‹ç”¨æ³•\n",
      "test_list = [3, 6, 8, 10, 1, 2, 1]\n",
      "sorted_list = quick_sort(test_list)\n",
      "print(sorted_list)\n",
      "```\n",
      "\n",
      "åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œ`quick_sort` å‡½æ•°å®ç°äº†å¿«é€Ÿæ’åºç®—æ³•ã€‚å®ƒé¦–å…ˆæ£€æŸ¥åˆ—è¡¨çš„é•¿åº¦ï¼Œå¦‚æœé•¿åº¦å°äºç­‰äº1ï¼Œç›´æ¥è¿”å›è¯¥åˆ—è¡¨ï¼Œå› ä¸ºå®ƒå·²ç»æ˜¯æœ‰åºçš„ã€‚ç„¶åé€‰æ‹©åˆ—è¡¨ä¸­é—´çš„å…ƒç´ ä½œä¸ºåŸºå‡†å€¼ `pivot` ï¼Œæ¥ç€å°†åˆ—è¡¨åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šå°äºåŸºå‡†å€¼çš„å…ƒç´ ç»„æˆçš„ `left` åˆ—è¡¨ã€ç­‰äºåŸºå‡†å€¼çš„å…ƒç´ ç»„æˆçš„ `middle` åˆ—è¡¨å’Œå¤§äºåŸºå‡†å€¼çš„å…ƒç´ ç»„æˆçš„ `right` åˆ—è¡¨ã€‚æœ€åé€šè¿‡é€’å½’åœ°å¯¹ `left` å’Œ `right` åˆ—è¡¨è¿›è¡Œå¿«é€Ÿæ’åºï¼Œå¹¶å°†ç»“æœä¸ `middle` åˆ—è¡¨åˆå¹¶ï¼Œå¾—åˆ°ä¸€ä¸ªæœ‰åºçš„åˆ—è¡¨ã€‚\n",
      "\n",
      "åœ¨ç¤ºä¾‹ç”¨æ³•éƒ¨åˆ†ï¼Œå®šä¹‰äº†ä¸€ä¸ªæµ‹è¯•åˆ—è¡¨ `test_list` ï¼Œè°ƒç”¨ `quick_sort` å‡½æ•°å¯¹å…¶è¿›è¡Œæ’åºï¼Œå¹¶æ‰“å°æ’åºåçš„ç»“æœã€‚ \n",
      "\n",
      "\n",
      "--- å®Œæ•´æ¨¡å‹å“åº” ---\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "    return quick_sort(left) + middle + quick_sort(right)\n",
      "```\n",
      "\n",
      "ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼š\n",
      "```python\n",
      "# ç¤ºä¾‹ç”¨æ³•\n",
      "test_list = [3, 6, 8, 10, 1, 2, 1]\n",
      "sorted_list = quick_sort(test_list)\n",
      "print(sorted_list)\n",
      "```\n",
      "\n",
      "åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œ`quick_sort` å‡½æ•°å®ç°äº†å¿«é€Ÿæ’åºç®—æ³•ã€‚å®ƒé¦–å…ˆæ£€æŸ¥åˆ—è¡¨çš„é•¿åº¦ï¼Œå¦‚æœé•¿åº¦å°äºç­‰äº1ï¼Œç›´æ¥è¿”å›è¯¥åˆ—è¡¨ï¼Œå› ä¸ºå®ƒå·²ç»æ˜¯æœ‰åºçš„ã€‚ç„¶åé€‰æ‹©åˆ—è¡¨ä¸­é—´çš„å…ƒç´ ä½œä¸ºåŸºå‡†å€¼ `pivot` ï¼Œæ¥ç€å°†åˆ—è¡¨åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šå°äºåŸºå‡†å€¼çš„å…ƒç´ ç»„æˆçš„ `left` åˆ—è¡¨ã€ç­‰äºåŸºå‡†å€¼çš„å…ƒç´ ç»„æˆçš„ `middle` åˆ—è¡¨å’Œå¤§äºåŸºå‡†å€¼çš„å…ƒç´ ç»„æˆçš„ `right` åˆ—è¡¨ã€‚æœ€åé€šè¿‡é€’å½’åœ°å¯¹ `left` å’Œ `right` åˆ—è¡¨è¿›è¡Œå¿«é€Ÿæ’åºï¼Œå¹¶å°†ç»“æœä¸ `middle` åˆ—è¡¨åˆå¹¶ï¼Œå¾—åˆ°ä¸€ä¸ªæœ‰åºçš„åˆ—è¡¨ã€‚\n",
      "\n",
      "åœ¨ç¤ºä¾‹ç”¨æ³•éƒ¨åˆ†ï¼Œå®šä¹‰äº†ä¸€ä¸ªæµ‹è¯•åˆ—è¡¨ `test_list` ï¼Œè°ƒç”¨ `quick_sort` å‡½æ•°å¯¹å…¶è¿›è¡Œæ’åºï¼Œå¹¶æ‰“å°æ’åºåçš„ç»“æœã€‚ \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "\n",
    "# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "class HelloAgentsLLM:\n",
    "    \"\"\"\n",
    "    ä¸ºæœ¬ä¹¦ \"Hello Agents\" å®šåˆ¶çš„LLMå®¢æˆ·ç«¯ã€‚\n",
    "    å®ƒç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ï¼Œå¹¶é»˜è®¤ä½¿ç”¨æµå¼å“åº”ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚\n",
    "        \"\"\"\n",
    "        self.model = model or os.getenv(\"LLM_MODEL_ID\")\n",
    "        apiKey = apiKey or os.getenv(\"LLM_API_KEY\")\n",
    "        baseUrl = baseUrl or os.getenv(\"LLM_BASE_URL\")\n",
    "        timeout = timeout or int(os.getenv(\"LLM_TIMEOUT\", 60))\n",
    "        \n",
    "        if not all([self.model, apiKey, baseUrl]):\n",
    "            raise ValueError(\"æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚\")\n",
    "\n",
    "        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)\n",
    "\n",
    "    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:\n",
    "        \"\"\"\n",
    "        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...\")\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                stream=True,\n",
    "            )\n",
    "            \n",
    "            # å¤„ç†æµå¼å“åº”\n",
    "            print(\"âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\")\n",
    "            collected_content = []\n",
    "            for chunk in response:\n",
    "                content = chunk.choices[0].delta.content or \"\"\n",
    "                print(content, end=\"\", flush=True)\n",
    "                collected_content.append(content)\n",
    "            print()  # åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ\n",
    "            return \"\".join(collected_content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            return None\n",
    "\n",
    "# --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        llmClient = HelloAgentsLLM()\n",
    "        \n",
    "        exampleMessages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes Python code.\"},\n",
    "            {\"role\": \"user\", \"content\": \"å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•\"}\n",
    "        ]\n",
    "        \n",
    "        print(\"--- è°ƒç”¨LLM ---\")\n",
    "        responseText = llmClient.think(exampleMessages)\n",
    "        if responseText:\n",
    "            print(\"\\n\\n--- å®Œæ•´æ¨¡å‹å“åº” ---\")\n",
    "            print(responseText)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# >>>\n",
    "# --- è°ƒç”¨LLM ---\n",
    "# ğŸ§  æ­£åœ¨è°ƒç”¨ xxxxxx æ¨¡å‹...\n",
    "# âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "# å¿«é€Ÿæ’åºæ˜¯ä¸€ç§éå¸¸é«˜æ•ˆçš„æ’åºç®—æ³•..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4554c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import SerpApiClient\n",
    "\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªåŸºäºSerpApiçš„å®æˆ˜ç½‘é¡µæœç´¢å¼•æ“å·¥å…·ã€‚\n",
    "    å®ƒä¼šæ™ºèƒ½åœ°è§£ææœç´¢ç»“æœï¼Œä¼˜å…ˆè¿”å›ç›´æ¥ç­”æ¡ˆæˆ–çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: {query}\")\n",
    "    try:\n",
    "        api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "        if not api_key:\n",
    "            return \"é”™è¯¯:SERPAPI_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­é…ç½®ã€‚\"\n",
    "\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": query,\n",
    "            \"api_key\": api_key,\n",
    "            \"gl\": \"cn\",  # å›½å®¶ä»£ç \n",
    "            \"hl\": \"zh-cn\", # è¯­è¨€ä»£ç \n",
    "        }\n",
    "        \n",
    "        client = SerpApiClient(params)\n",
    "        results = client.get_dict()\n",
    "        \n",
    "        # æ™ºèƒ½è§£æ:ä¼˜å…ˆå¯»æ‰¾æœ€ç›´æ¥çš„ç­”æ¡ˆ\n",
    "        if \"answer_box_list\" in results:\n",
    "            return \"\\n\".join(results[\"answer_box_list\"])\n",
    "        if \"answer_box\" in results and \"answer\" in results[\"answer_box\"]:\n",
    "            return results[\"answer_box\"][\"answer\"]\n",
    "        if \"knowledge_graph\" in results and \"description\" in results[\"knowledge_graph\"]:\n",
    "            return results[\"knowledge_graph\"][\"description\"]\n",
    "        if \"organic_results\" in results and results[\"organic_results\"]:\n",
    "            # å¦‚æœæ²¡æœ‰ç›´æ¥ç­”æ¡ˆï¼Œåˆ™è¿”å›å‰ä¸‰ä¸ªæœ‰æœºç»“æœçš„æ‘˜è¦\n",
    "            snippets = [\n",
    "                f\"[{i+1}] {res.get('title', '')}\\n{res.get('snippet', '')}\"\n",
    "                for i, res in enumerate(results[\"organic_results\"][:3])\n",
    "            ]\n",
    "            return \"\\n\\n\".join(snippets)\n",
    "        \n",
    "        return f\"å¯¹ä¸èµ·ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äº '{query}' çš„ä¿¡æ¯ã€‚\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020e01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "class ToolExecutor:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªå·¥å…·æ‰§è¡Œå™¨ï¼Œè´Ÿè´£ç®¡ç†å’Œæ‰§è¡Œå·¥å…·ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def registerTool(self, name: str, description: str, func: callable):\n",
    "        \"\"\"\n",
    "        å‘å·¥å…·ç®±ä¸­æ³¨å†Œä¸€ä¸ªæ–°å·¥å…·ã€‚\n",
    "        \"\"\"\n",
    "        if name in self.tools:\n",
    "            print(f\"è­¦å‘Š:å·¥å…· '{name}' å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ã€‚\")\n",
    "        self.tools[name] = {\"description\": description, \"func\": func}\n",
    "        print(f\"å·¥å…· '{name}' å·²æ³¨å†Œã€‚\")\n",
    "\n",
    "    def getTool(self, name: str) -> callable:\n",
    "        \"\"\"\n",
    "        æ ¹æ®åç§°è·å–ä¸€ä¸ªå·¥å…·çš„æ‰§è¡Œå‡½æ•°ã€‚\n",
    "        \"\"\"\n",
    "        return self.tools.get(name, {}).get(\"func\")\n",
    "\n",
    "    def getAvailableTools(self) -> str:\n",
    "        \"\"\"\n",
    "        è·å–æ‰€æœ‰å¯ç”¨å·¥å…·çš„æ ¼å¼åŒ–æè¿°å­—ç¬¦ä¸²ã€‚\n",
    "        \"\"\"\n",
    "        return \"\\n\".join([\n",
    "            f\"- {name}: {info['description']}\" \n",
    "            for name, info in self.tools.items()\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46ea81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·¥å…· 'Search' å·²æ³¨å†Œã€‚\n",
      "\n",
      "--- å¯ç”¨çš„å·¥å…· ---\n",
      "- Search: ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\n",
      "\n",
      "--- æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ'] ---\n",
      "ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\n",
      "--- è§‚å¯Ÿ (Observation) ---\n",
      "[1] æ¯”è¾ƒGeForce ç³»åˆ—æœ€æ–°ä¸€ä»£æ˜¾å¡å’Œå‰ä»£æ˜¾å¡\n",
      "æ¯”è¾ƒæœ€æ–°ä¸€ä»£RTX 30 ç³»åˆ—æ˜¾å¡å’Œå‰ä»£çš„RTX 20 ç³»åˆ—ã€GTX 10 å’Œ900 ç³»åˆ—æ˜¾å¡ã€‚æŸ¥çœ‹è§„æ ¼ã€åŠŸèƒ½ã€æŠ€æœ¯æ”¯æŒç­‰å†…å®¹ã€‚\n",
      "\n",
      "[2] GeForce RTX 50 ç³»åˆ—æ˜¾å¡\n",
      "GeForce RTXâ„¢ 50 ç³»åˆ—GPU æ­è½½NVIDIA Blackwell æ¶æ„ï¼Œä¸ºæ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…å¸¦æ¥å…¨æ–°ç©æ³•ã€‚RTX 50 ç³»åˆ—å…·å¤‡å¼ºå¤§çš„AI ç®—åŠ›ï¼Œå¸¦æ¥å‡çº§ä½“éªŒå’Œæ›´é€¼çœŸçš„ç”»é¢ã€‚\n",
      "\n",
      "[3] ä¸€æ–‡å½»åº•è¯»æ‡‚ï¼šè‹±ä¼Ÿè¾¾GPUåˆ†ç±»ã€æ¶æ„æ¼”è¿›å’Œå‚æ•°è§£æ\n",
      "Quadroç³»åˆ—æ˜¯è‹±ä¼Ÿè¾¾ä¸“ä¸šçº§GPUäº§å“çº¿ï¼Œé’ˆå¯¹å•†ä¸šå’Œä¸“ä¸šåº”ç”¨é¢†åŸŸè¿›è¡Œäº†ä¼˜åŒ–ã€‚å¸¸è§çš„äº§å“å‹å·å¦‚NVIDIA RTX A6000ã€A5000ç­‰ã€‚ Quadro GPUå…·å¤‡å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ã€å¤§ ...\n"
     ]
    }
   ],
   "source": [
    "# --- å·¥å…·åˆå§‹åŒ–ä¸ä½¿ç”¨ç¤ºä¾‹ ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨\n",
    "    toolExecutor = ToolExecutor()\n",
    "\n",
    "    # 2. æ³¨å†Œæˆ‘ä»¬çš„å®æˆ˜æœç´¢å·¥å…·\n",
    "    search_description = \"ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\"\n",
    "    toolExecutor.registerTool(\"Search\", search_description, search)\n",
    "    \n",
    "    # 3. æ‰“å°å¯ç”¨çš„å·¥å…·\n",
    "    print(\"\\n--- å¯ç”¨çš„å·¥å…· ---\")\n",
    "    print(toolExecutor.getAvailableTools())\n",
    "\n",
    "    # 4. æ™ºèƒ½ä½“çš„Actionè°ƒç”¨ï¼Œè¿™æ¬¡æˆ‘ä»¬é—®ä¸€ä¸ªå®æ—¶æ€§çš„é—®é¢˜\n",
    "    print(\"\\n--- æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ'] ---\")\n",
    "    tool_name = \"Search\"\n",
    "    tool_input = \"è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\"\n",
    "\n",
    "    tool_function = toolExecutor.getTool(tool_name)\n",
    "    if tool_function:\n",
    "        observation = tool_function(tool_input)\n",
    "        print(\"--- è§‚å¯Ÿ (Observation) ---\")\n",
    "        print(observation)\n",
    "    else:\n",
    "        print(f\"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚\")\n",
    "        \n",
    "# >>>\n",
    "# å·¥å…· 'Search' å·²æ³¨å†Œã€‚\n",
    "\n",
    "# --- å¯ç”¨çš„å·¥å…· ---\n",
    "# - Search: ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚\n",
    "\n",
    "# --- æ‰§è¡Œ Action: Search['è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ'] ---\n",
    "# ğŸ” æ­£åœ¨æ‰§è¡Œ [SerpApi] ç½‘é¡µæœç´¢: è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·æ˜¯ä»€ä¹ˆ\n",
    "# --- è§‚å¯Ÿ (Observation) ---\n",
    "# [1] GeForce RTX 50 ç³»åˆ—æ˜¾å¡\n",
    "# GeForce RTXâ„¢ 50 ç³»åˆ—GPU æ­è½½NVIDIA Blackwell æ¶æ„ï¼Œä¸ºæ¸¸æˆç©å®¶å’Œåˆ›ä½œè€…å¸¦æ¥å…¨æ–°ç©æ³•ã€‚RTX 50 ç³»åˆ—å…·å¤‡å¼ºå¤§çš„AI ç®—åŠ›ï¼Œå¸¦æ¥å‡çº§ä½“éªŒå’Œæ›´é€¼çœŸçš„ç”»é¢ã€‚\n",
    "\n",
    "# [2] æ¯”è¾ƒGeForce ç³»åˆ—æœ€æ–°ä¸€ä»£æ˜¾å¡å’Œå‰ä»£æ˜¾å¡\n",
    "# æ¯”è¾ƒæœ€æ–°ä¸€ä»£RTX 30 ç³»åˆ—æ˜¾å¡å’Œå‰ä»£çš„RTX 20 ç³»åˆ—ã€GTX 10 å’Œ900 ç³»åˆ—æ˜¾å¡ã€‚æŸ¥çœ‹è§„æ ¼ã€åŠŸèƒ½ã€æŠ€æœ¯æ”¯æŒç­‰å†…å®¹ã€‚\n",
    "\n",
    "# [3] GeForce æ˜¾å¡| NVIDIA\n",
    "# DRIVE AGX. å¼ºå¤§çš„è½¦è½½è®¡ç®—èƒ½åŠ›ï¼Œé€‚ç”¨äºAI é©±åŠ¨çš„æ™ºèƒ½æ±½è½¦ç³»ç»Ÿ Â· Clara AGX. é€‚ç”¨äºåˆ›æ–°å‹åŒ»ç–—è®¾å¤‡å’Œæˆåƒçš„AI è®¡ç®—. æ¸¸æˆå’Œåˆ›ä½œ. GeForce. æ¢ç´¢æ˜¾å¡ã€æ¸¸æˆè§£å†³æ–¹æ¡ˆã€AI ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f3366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct æç¤ºè¯æ¨¡æ¿\n",
    "REACT_PROMPT_TEMPLATE = \"\"\"\n",
    "è¯·æ³¨æ„ï¼Œä½ æ˜¯ä¸€ä¸ªæœ‰èƒ½åŠ›è°ƒç”¨å¤–éƒ¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚\n",
    "\n",
    "å¯ç”¨å·¥å…·å¦‚ä¸‹:\n",
    "{tools}\n",
    "\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿›è¡Œå›åº”:\n",
    "\n",
    "Thought: ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç”¨äºåˆ†æé—®é¢˜ã€æ‹†è§£ä»»åŠ¡å’Œè§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚\n",
    "Action: ä½ å†³å®šé‡‡å–çš„è¡ŒåŠ¨ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€:\n",
    "- `{{tool_name}}[{{tool_input}}]`:è°ƒç”¨ä¸€ä¸ªå¯ç”¨å·¥å…·ã€‚\n",
    "- `Finish[æœ€ç»ˆç­”æ¡ˆ]`:å½“ä½ è®¤ä¸ºå·²ç»è·å¾—æœ€ç»ˆç­”æ¡ˆæ—¶ã€‚\n",
    "- å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨Action:å­—æ®µåä½¿ç”¨ finish(answer=\"...\") æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œè¯·å¼€å§‹è§£å†³ä»¥ä¸‹é—®é¢˜:\n",
    "Question: {question}\n",
    "History: {history}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b88d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class ReActAgent:\n",
    "    def __init__(self, llm_client: HelloAgentsLLM, tool_executor: ToolExecutor, max_steps: int = 5):\n",
    "        self.llm_client = llm_client\n",
    "        self.tool_executor = tool_executor\n",
    "        self.max_steps = max_steps\n",
    "        self.history = []\n",
    "\n",
    "    def _parse_output(self, text: str):\n",
    "        \"\"\"è§£æLLMçš„è¾“å‡ºï¼Œæå–Thoughtå’ŒActionã€‚\"\"\"\n",
    "        thought_match = re.search(r\"Thought: (.*)\", text)\n",
    "        action_match = re.search(r\"Action: (.*)\", text)\n",
    "        thought = thought_match.group(1).strip() if thought_match else None\n",
    "        action = action_match.group(1).strip() if action_match else None\n",
    "        return thought, action\n",
    "\n",
    "    def _parse_action(self, action_text: str):\n",
    "        \"\"\"è§£æActionå­—ç¬¦ä¸²ï¼Œæå–å·¥å…·åç§°å’Œè¾“å…¥ã€‚\"\"\"\n",
    "        match = re.match(r\"(\\w+)\\[(.*)\\]\", action_text)\n",
    "        if match:\n",
    "            return match.group(1), match.group(2)\n",
    "        return None, None\n",
    "\n",
    "    def run(self, question: str):\n",
    "        \"\"\"\n",
    "        è¿è¡ŒReActæ™ºèƒ½ä½“æ¥å›ç­”ä¸€ä¸ªé—®é¢˜ã€‚\n",
    "        \"\"\"\n",
    "        self.history = [] # æ¯æ¬¡è¿è¡Œæ—¶é‡ç½®å†å²è®°å½•\n",
    "        current_step = 0\n",
    "\n",
    "        while current_step < self.max_steps:\n",
    "            current_step += 1\n",
    "            print(f\"--- ç¬¬ {current_step} æ­¥ ---\")\n",
    "\n",
    "            # 1. æ ¼å¼åŒ–æç¤ºè¯\n",
    "            tools_desc = self.tool_executor.getAvailableTools()\n",
    "            history_str = \"\\n\".join(self.history)\n",
    "            prompt = REACT_PROMPT_TEMPLATE.format(\n",
    "                tools=tools_desc,\n",
    "                question=question,\n",
    "                history=history_str\n",
    "            )\n",
    "\n",
    "            # 2. è°ƒç”¨LLMè¿›è¡Œæ€è€ƒ\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response_text = self.llm_client.think(messages=messages)\n",
    "            \n",
    "            if not response_text:\n",
    "                print(\"é”™è¯¯:LLMæœªèƒ½è¿”å›æœ‰æ•ˆå“åº”ã€‚\")\n",
    "                break\n",
    "\n",
    "            # 3. è§£æLLMçš„è¾“å‡º\n",
    "            thought, action = self._parse_output(response_text)\n",
    "            \n",
    "            if thought:\n",
    "                print(f\"æ€è€ƒ: {thought}\")\n",
    "\n",
    "            if not action:\n",
    "                print(\"è­¦å‘Š:æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„Actionï¼Œæµç¨‹ç»ˆæ­¢ã€‚\")\n",
    "                break\n",
    "\n",
    "            # 4. æ‰§è¡ŒAction\n",
    "            if action.startswith(\"Finish\"):\n",
    "                # å¦‚æœæ˜¯FinishæŒ‡ä»¤ï¼Œæå–æœ€ç»ˆç­”æ¡ˆå¹¶ç»“æŸ\n",
    "                final_answer = re.match(r\"Finish\\[(.*)\\]\", action).group(1)\n",
    "                print(f\"ğŸ‰ æœ€ç»ˆç­”æ¡ˆ: {final_answer}\")\n",
    "                return final_answer\n",
    "            \n",
    "            tool_name, tool_input = self._parse_action(action)\n",
    "            if not tool_name or not tool_input:\n",
    "                # ... å¤„ç†æ— æ•ˆActionæ ¼å¼ ...\n",
    "                continue\n",
    "\n",
    "            print(f\"ğŸ¬ è¡ŒåŠ¨: {tool_name}[{tool_input}]\")\n",
    "            \n",
    "            tool_function = self.tool_executor.getTool(tool_name)\n",
    "            if not tool_function:\n",
    "                observation = f\"é”™è¯¯:æœªæ‰¾åˆ°åä¸º '{tool_name}' çš„å·¥å…·ã€‚\"\n",
    "            else:\n",
    "                observation = tool_function(tool_input) # è°ƒç”¨çœŸå®å·¥å…·\n",
    "        \n",
    "            print(f\"ğŸ‘€ è§‚å¯Ÿ: {observation}\")\n",
    "            \n",
    "            # å°†æœ¬è½®çš„Actionå’ŒObservationæ·»åŠ åˆ°å†å²è®°å½•ä¸­\n",
    "            self.history.append(f\"Action: {action}\")\n",
    "            self.history.append(f\"Observation: {observation}\")\n",
    "\n",
    "        # å¾ªç¯ç»“æŸ\n",
    "        print(\"å·²è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼Œæµç¨‹ç»ˆæ­¢ã€‚\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdd1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
