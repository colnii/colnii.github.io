打卡，感觉第一天的打卡内容还是比较简单的，因为之前有一定学习了解，能跟上。感觉因为代码基础比较缺乏，甚至之前一直不了解为什么json提取的内容经常要带上[0]，今天读代码的时候才好好去过了一遍。

之前的工作内容有遇到很多需要正则解决的问题，但是我一直不是很懂正则，这次看到1.3.3的正则又有点昏头，还得练

接下来是做作业：

1. ABCD从广义上都是智能体，但分别由低到高对应只能体的四个阶段，从反射到基于模型到基于目标再到基于效用。

2.
P:在结构化的各项生理数据的基础上，最大化用户健身与运动的效能
E:传感器数据，用户目标
A:调用文字转语音api或语音大模型
S:解析传感器的各项数据，读取用户输入的自然语言

3.
1)、A相对稳定，但缺乏变通性，依赖人工
2)、B具有更强的变通性和人情味，但容易因为AI的不稳定造成损失
3)、C 构建多agent系统，必要的时候允许ai调用客服审核；还可以设计RAG系统或是强化学习，通过参考人工的客户处理方式让ai回答更稳定

4.
1)、写一个memory_record的function和对应的提示词，加入到available_tools 和 AGENT_SYSTEM_PROMPT里，调用memory_record并传入的内容就添加到模型的system_prompt内
2)、如果购票是用户返回的话改一下提示词就行，是api返回的话就可以写一个循环流程，让ai多轮修改方案，直到成功订票或超出循环上限
3)、在有memory的前提下可以每次循环finish让用户都能通过Y/N回复决定AI方案，但这样不是每轮都能拒绝推荐吗？感觉有点不太理解

5.
1/2)、1/2混合推理，2，1
3)、感觉可以参考类似MoE这样的门控系统？

6.
1)、大语言模型只是爬取了人类的大部分数据，就算除去数据采集时的人工筛选，也会混入大量无效信息，大模型本身只是出现次数/概率大的句子/信息，gpt模型本身无法对自己输出信息前就判断出到底有没有生成正确的内容，这也就是为什么思考推理模型在数学等方面的能力会强上一些，因为“思考”的强化学习训练使得模型在输出信息后有更多的机会进行反思了
2)、无限循环
3)、准确度是一个指标，“智能”这个词本身就是人类对自身行动力的一个总称，所以必然需要更多维度的判断标准，但目前而言可以量化的方面并不多，目前比较好的方向也只是通过RLHF等方式进行人类偏好的对齐
